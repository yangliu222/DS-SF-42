{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to `scikit-learn` and Linear Regression\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "<br>\n",
    "<img src=\"https://i.imgur.com/ZIOIrAd.png\" style=\"width: 500px; float: left; margin: 20px; margin-top: -20px; break: right;\">\n",
    "<br clear=\"all\">\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Define data modeling and simple linear regression\n",
    "- Fit a simple and multi-linear regression with sklearn\n",
    "- Interpret the coefficients of a linear regression model\n",
    "- State the benefits and pitfalls of a multi-linear regression\n",
    "- Assess model fit by checking assumptions and analyzing regression metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple linear regression\n",
    "---\n",
    "The simple linear regression aims to capture a linear relationship between a target and a single predictor.\n",
    "\n",
    "$$\\hat{y} = b_0 + b_1 \\cdot x_1$$\n",
    "\n",
    "e.g. \n",
    "\n",
    "$$\\hat{SalePrice} = 200,000 + 5,000 \\cdot Sqrft$$\n",
    "\n",
    "This linear equation _**is**_ your regression model. You feed it the square footage of homes and it will spit out predictions for the sale prices.\n",
    "\n",
    "### <font color=blue>Discussion -</font> How do you verbally interpret these coefficients? What is the equivalent for KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sklearn-first-steps'></a>\n",
    "\n",
    "## First steps with `sklearn`: loading the data\n",
    "\n",
    "---\n",
    "\n",
    "We will load the boston housing dataset using sklearn and then construct and fit a linear regression model on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Don't forget to turn on plotting display in the notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the boston housing data with the `datasets.load_boston()` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_boston()\n",
    "\n",
    "print data.DESCR # This is like a data dictionary!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data object we've loaded has attributes with the features, target variable, and design matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print data.feature_names\n",
    "print data.data[0:3]\n",
    "print data.target[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the data in pandas for convenience\n",
    "\n",
    "Our target is what we are predicting.  Sometimes this is called the **response variable**.\n",
    "\n",
    "The target and the data are what we use to train, or **fit** the model with.\n",
    "\n",
    "Scikit-learn has already split our data into the **predictors** and **response** for us. It has also stored the names of the features in a separate array. \n",
    "\n",
    "So we can print things like the header of the data it will be more convenient to have our data in a pandas dataframe.\n",
    "\n",
    "**Use the predictors and the feature names to create a pandas dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create dataframe of main data to use as predictors (later). AKA \"X\"\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "\n",
    "# target vector (MEDV)\n",
    "target = data.target\n",
    "\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set is a matrix / dataframe with many variables (**CRI, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B,** and **LSTAT**). We have **13** predictors with **506** rows/observations.\n",
    "\n",
    "Our target is a vector that represents a single variable (**MEDV**), which has exactly the same number of observations as our training set: **506**.\n",
    "\n",
    "> _Training (fit) and target datasets must always match in length!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first-model-sklearn'></a>\n",
    "\n",
    "## Fitting our 1st model with `sklearn`\n",
    "\n",
    "---\n",
    "\n",
    "Now let's fit a linear regression model with the housing data. \n",
    "\n",
    "First let's visually identify some predictors that seem to have a relationship with house value. \n",
    "\n",
    "**Plot RM and LSTAT against the target variable with seaborn.** \n",
    "\n",
    "> _Note: If for some reason scikit-learn crashes the jupyter notebook, have conda remove mkl (there's an issue with the newer build on some systems)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(df.RM.values, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(df.LSTAT.values, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below we fit a linear regression model predicting `MEDV` (the target vector) from `RM`.**\n",
    "\n",
    "> **Note:** sklearn models expect the predictor matrix to be 2D and the target to be 1D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "\n",
    "X = df[[\"RM\"]]\n",
    "y = target \n",
    "\n",
    "model = lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions for the X matrix using `.predict(X)`, and score the model ($R^2$) using `model.score(X, y)`.**\n",
    "\n",
    "Plot the predicted values against the true values of the target, and print the model $R^2$.\n",
    "\n",
    "> **`.score(predictors, target)`**: a class method / function that returns the coefficient of determination R^2 of the prediction (for regression models).  Found in many models in scikit-learn (but not all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X)\n",
    "score = model.score(X, y)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values from RM - $\\hat{y}$\")\n",
    "plt.ylabel(\"Actual Values MEDV - y\")\n",
    "plt.show()\n",
    "\n",
    "print \"score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can this plot tell us about the model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-attributes'></a>\n",
    "\n",
    "## sklearn model class attributes\n",
    "\n",
    "---\n",
    "\n",
    "After you run `.fit()`, a sklearn model object often contains a variety of calculated metrics, coefficients, and other information. Which metrics and attributes are present will depend on the model â€“ consult the documentation for specifics. \n",
    "\n",
    "Attributes in the `LinearRegression` object include:\n",
    "- **`.coef_`**: property containing the coeffients for the predictor variables\n",
    "- **`.intercept_`**: value of the intercept\n",
    "\n",
    "**Print out the beta coefficient and intercept for the model.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.coef_\n",
    "print model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting regression coefficients\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='common-metrics'></a>\n",
    "\n",
    "## Metrics for evaluating regression models\n",
    "\n",
    "\n",
    "As we venture down the path of modeling, it can be difficult to determine which choices are \"correct\" or \"incorrect\".  A primary challenge is to understand how different models will perform in different circumstances and different types of data. It's essential to practice modeling on a variety of data.\n",
    "\n",
    "As a beginner it is essential to learn which metrics are important for evaluating your models and what they mean. The metrics we evaluate our models with inform our actions.  \n",
    "\n",
    "*Exploring datasets on your own with the skills and tools you learn in class is highly recommended!*\n",
    "\n",
    "---\n",
    "\n",
    "### The $R^2$, aka \"coefficient of determination\"\n",
    "\n",
    "The primary regression metric is the $R^2$. It ranges from negative infinity to 1.  \n",
    "\n",
    "### $$ R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} $$\n",
    "\n",
    "Where the residual sum of squares is the sum of squared residuals for our model:\n",
    "\n",
    "$SS_{res}=\\sum_i (y_i - \\hat{y})^2$\n",
    "\n",
    "And the total sum of squares is the sum of squared residuals if all of your predictions were just the mean of the outcome value in the training set. In other words, this is the variance of your target.\n",
    "\n",
    "$SS_{tot} = \\sum_i (y_i-\\bar{y})^2$\n",
    "\n",
    "#### Visual intution\n",
    "Let's play around with this [interactive plotter](http://illuminations.nctm.org/activity.aspx?id=6817) for residual sum of squares.\n",
    "\n",
    "$R^2$ is the most common metric to evaluate a regression and is the default scoring measure in sklearn, just like how for KNN (and other classification models the `.score` function defaults to accuracy.\n",
    "\n",
    "### Unscaled metrics: _mean squared error_ and _mean absolute error_ \n",
    "\n",
    "#### Mean squared error (MSE)\n",
    "\"The average squared residual\". This is the actual quantity that the linear regression model minimizes to fit the beta coefficients to the data. A large MSE is bad; small is better.\n",
    "### $$MSE = \\frac{1}{N}\\sum_{i=0}^{N}(y_i - \\hat{y_i})^2$$\n",
    "\n",
    "\n",
    "#### Mean absolute error (MAE)\n",
    "\n",
    "### $$MAE = \\frac{1}{N}\\sum_{i=0}^{N}\\left|y_i - \\hat{y_i}\\right|$$\n",
    "\n",
    "### <font color=blue>Discussion - </font> What are the advantages and the tradeoffs of these three metrics?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's calculate the mean absolute error \"by hand\" of our model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>Independent - </font> Calculate the $R^2$ of our model's predictions on the boston dataset.\n",
    "First calculated it \"by hand\" using numpy or pandas as your calculator. Then check your answer with the function from the `sklearn.metrics` module. You are going to need to compare the predicted and actual `MEDV` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mlr-sklearn'></a>\n",
    "\n",
    "## Fit a Multi-linear regression using sklearn\n",
    "\n",
    "---\n",
    "Why limit ourself to one predictor column? Our target is probably linearly impacted by many variables.\n",
    "\n",
    "$$Income = b_0 + b_1 \\cdot Seniority\\, + \\, b_2\\cdot EducationYears$$\n",
    "\n",
    "\n",
    "<img src=https://i.imgur.com/apd97rl.png width=\"75%\">\n",
    "\n",
    "We have fit a simple linear regression predicting `MEDV ~ RM + 1` (where the 1 represents the intercept). Use the same sklearn process and `LinearRegression` model to estimate the target with both `RM` and `LSTAT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = linear_model.LinearRegression()\n",
    "\n",
    "X = df[[\"RM\",\"LSTAT\"]].values\n",
    "y = target \n",
    "\n",
    "model = lm.fit(X, y)\n",
    "\n",
    "predictions =  model.predict(X)\n",
    "score = model.score(X, y)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values from RM + LSTAT - $\\hat{y}$\")\n",
    "plt.ylabel(\"Actual Values MEDV - y\")\n",
    "plt.show()\n",
    "\n",
    "print \"score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the coefficients from this MLR model and interpret them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### <font color=blue>Discussion - </font> How do we interpret the coefficients in a multi-linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='negative-r2'></a>\n",
    "\n",
    "## A note on negative $R^2$ values\n",
    "\n",
    "---\n",
    "\n",
    "Over the course of this class you will encounter negative $R^2$ values. This may seem impossible, and it is in the standard scenario where we are calculating the $R^2$ score on the data we fit the model with.\n",
    "\n",
    "However, if you fit your model on one sample of data, *then score the model on new data not used to fit the model*, it is possible to end up with negative $R^2$.\n",
    "\n",
    "**What does it mean to have a negative $R^2$?**\n",
    "\n",
    "Remember that $R^2$ is 1 minus the error of your regression model divided by the error of the baseline model. A negative $R^2$ means that the regression model is performing *worse* than the baseline model. In the context of fitting our data on one sample of data and scoring on another sample, this means that we would have been better off making predictions on the test sample just using the mean of the target variable in our training set.\n",
    "\n",
    "We will return to the topic of negative $R^2$ when we talk about training and testing sets and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='independent-practice'></a>\n",
    "\n",
    "## Independent practice\n",
    "\n",
    "---\n",
    "\n",
    "Build a model using any set of **continuous** variables of your choice. Evaluate your model using $R^2$. Describe what the $R^2$ means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "---\n",
    "\n",
    "- Linear regression seeks a linear relationship between a continuous target and one or more predictors\n",
    "- Interpret coefficients as \"The expected change in the target when predictor ____ is increased by one unit, if all else is held equal\"\n",
    "- Common regression metrics are $R^2$, mean squared error, and mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ds42)",
   "language": "python",
   "name": "ds42"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
