{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Bagging and Ensembling with Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<b> Goals </b>\n",
    "\n",
    "- Random Forest model: the ins and outs and how it relates to Decision Trees. Our first **black box** model.\n",
    "- The concept of bagging and ensembling in the context of machine learning and specifically the Random Forest model.\n",
    "- Compare and contrast Decision Trees with Random Forest using both the regression and classification of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Ensembling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's pretend that instead of building a single model to solve a binary classification problem, you created **five independent models**, and each model was correct about 70% of the time. If you combined these models into an \"ensemble\" and used their majority vote as a prediction, how often would the ensemble be correct? Think wisdom of the crowds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# set a seed for reproducibility\n",
    "np.random.seed(1234)\n",
    "\n",
    "# generate 1000 random numbers (between 0 and 1) for each model, representing 1000 observations\n",
    "mod1 = np.random.rand(1000)\n",
    "mod2 = np.random.rand(1000)\n",
    "mod3 = np.random.rand(1000)\n",
    "mod4 = np.random.rand(1000)\n",
    "mod5 = np.random.rand(1000)\n",
    "\n",
    "# each model independently predicts 1 (the \"correct response\") if random number was at least 0.3\n",
    "preds1 = np.where(mod1 > 0.3, 1, 0)\n",
    "preds2 = np.where(mod2 > 0.3, 1, 0)\n",
    "preds3 = np.where(mod3 > 0.3, 1, 0)\n",
    "preds4 = np.where(mod4 > 0.3, 1, 0)\n",
    "preds5 = np.where(mod5 > 0.3, 1, 0)\n",
    "\n",
    "# print the first 20 predictions from each model\n",
    "print preds1[:20]\n",
    "print preds2[:20]\n",
    "print preds3[:20]\n",
    "print preds4[:20]\n",
    "print preds5[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# average the predictions and then round to 0 or 1\n",
    "ensemble_preds = np.round((preds1 + preds2 + preds3 + preds4 + preds5)/5.0).astype(int)\n",
    "\n",
    "# print the ensemble's first 20 predictions\n",
    "print ensemble_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# how accurate was each individual model?\n",
    "print preds1.mean()\n",
    "print preds2.mean()\n",
    "print preds3.mean()\n",
    "print preds4.mean()\n",
    "print preds5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# how accurate was the ensemble?\n",
    "print ensemble_preds.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Note:** As you add more models to the voting process, the probability of error decreases, which is known as [Condorcet's Jury Theorem](http://en.wikipedia.org/wiki/Condorcet%27s_jury_theorem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### What is ensembling?\n",
    "\n",
    "<br>\n",
    "\n",
    "**Ensemble learning (or \"ensembling\")** is the process of combining several predictive models in order to produce a combined model that is more accurate than any individual model. Ensemble models are basically models made up of other models. \n",
    "\n",
    "- **Regression:** take the average of the predictions\n",
    "- **Classification:** take a vote and use the most common prediction, or take the average of the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different processes\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "There are two basic **methods for ensembling:**\n",
    "\n",
    "- Manually ensemble your individual models\n",
    "- Use a model that ensembles for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Manual Ensembling\n",
    "![Machine learning flowchart](images/crowdflower_ensembling.jpg)\n",
    "\n",
    "*Machine learning flowchart created by the [winner](https://github.com/ChenglongChen/Kaggle_CrowdFlower) of Kaggle's [CrowdFlower competition](https://www.kaggle.com/c/crowdflower-search-relevance)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "What makes a good manual ensemble?\n",
    "\n",
    "- Different types of **models**\n",
    "- Different combinations of **features**\n",
    "- Different **tuning parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Comparing manual ensembling with a single model approach\n",
    "\n",
    "**Advantages of manual ensembling:**\n",
    "\n",
    "- Increases predictive accuracy\n",
    "- Easy to get started\n",
    "\n",
    "**Disadvantages of manual ensembling:**\n",
    "\n",
    "- Decreases interpretability\n",
    "- Takes longer to train\n",
    "- Takes longer to predict\n",
    "- More complex to automate and maintain\n",
    "- Small gains in accuracy may not be worth the added complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "As you may have already guessed, Random Forest is related to Decision Trees. Knowing what we know about Decision Trees, what do you think Random Forest does?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    "- Decision Tree is singular while Random Forest is plural. Instead of one decision, we have multiple, a whole forest of decisions.  \n",
    "- Each tree in the Random Forest gets a vote on deciding the outcome.\n",
    "- Random Forest is a type of Ensembling because these sub models are Decision Trees. Random Forest generates many Decision Trees and combines them to generate a single prediction through a voting process.\n",
    "- Random Forest usually better than Decision Trees because it's not as vulnerable to overfitting. This is why Random Forest has become such a popular algorithm for the data scientists.\n",
    "- Like Decision Trees, you can set the parameters such as maximum number of features. Random Forest also uses the same attributes to determine the split such as gini and [entropy](http://www.saedsayad.com/decision_tree.htm).\n",
    "- But perhaps the most significant parameter we have to set is the number of trees or estimators in our model, this means we have to \"tune\" this parameter in order to optimize our model.\n",
    "- Regression application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Bagging\n",
    "\n",
    "Random forest models do not just create a whole bunch of trees from the same data. They use <b>bagging</b> and a random selection of features to generate different trees. If they didn't use this, then the trees would all be very similar if not the same, which would almost eliminate the point of Random Forest.\n",
    "<br><br>\n",
    "<b>Bagging:</b>  General purpose procedure for reducing the variance of a machine learning method. Bagging is short for bootstrap aggregation, meaning the aggregation of bootstrap samples. What is a **bootstrap sample**? A random sample with replacement. \n",
    "\n",
    "<br>\n",
    "Each tree selects a sample of observations/events with replacement to build the training set. Replacement means it chooses the same observation multiple times â€” only an issue with very small sample datasets. Observation is put \"back in the bag\" for future use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**How does bagging work for Random Forest?**\n",
    "\n",
    "1. Grow B trees using B bootstrap samples from the training data.\n",
    "2. Train each tree on its bootstrap sample and make predictions.\n",
    "3. Combine the predictions:\n",
    "    - Average the predictions for **regression trees**\n",
    "    - Take a vote for **classification trees**\n",
    "\n",
    "Notes:\n",
    "\n",
    "- **Each bootstrap sample** should be the same size as the original training set.\n",
    "- **B** should be a large enough value that the error seems to have \"stabilized\".\n",
    "- The trees are **grown deep** so that they have low bias/high variance. Means we do not set max_depth.\n",
    "\n",
    "Bagging increases predictive accuracy by **reducing the variance**, similar to how cross-validation reduces the variance associated with train/test split (for estimating out-of-sample error) by splitting many times an averaging the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Random Forest uses a random selection of features for each split. This means for each time it has to perform a split or generate a rule, it is only looking at this random sample of the features as possibilities to generate that rule. This will help avoid the similarity problem because the trees will not be built with the same set features at every point. The number of features is usually determined by $\\sqrt{x}$ features are used for classifiers and $x/3$ for regression.\n",
    "<br><br>\n",
    "**Whats the point?**\n",
    "\n",
    "- Suppose there is **one very strong feature** in the data set. When using bagged trees, most of the trees will use that feature as the top split, resulting in an ensemble of similar trees that are **highly correlated**.\n",
    "- Averaging highly correlated quantities does not significantly reduce variance (which is the entire goal of bagging).\n",
    "- By randomly leaving out candidate features from each split, **Random Forests \"decorrelates\" the trees**, such that the averaging process can reduce the variance of the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Pros and Cons of Random Forest\n",
    "\n",
    "**Pros:**\n",
    "\n",
    "- No feature preparation such as scaling.\n",
    "- Effective, beats most ML algorithms.\n",
    "- Fast, can train using data very large in a reasonable amount of time.\n",
    "- It's hard to build a bad RF model.\n",
    "\n",
    "**Cons:**\n",
    "\n",
    "- Can grow to be way too large and complex. Models can literally take dozens of MBs in space.\n",
    "- Not interpretable like a Decision Tree.\n",
    "- Slower at training and predicting than Decision Trees.\n",
    "- Not great for when the focus is on probabilities.\n",
    "- Black box model qualities because there lacks some transparency in the modeling process. It's hard to gain insight into how it comes to conclusions.Requires a bit of faith from the data scientist. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Manually implementing bagged decision trees (with B=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We're going to use the vehicles dataset to demonstrate bagging for a regresion project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(1)\n",
    "\n",
    "# create an array of 1 through 20\n",
    "nums = np.arange(1, 21)\n",
    "print nums\n",
    "\n",
    "# sample that array 20 times with replacement\n",
    "print np.random.choice(a=nums, size=20, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read in and prepare the vehicle training data\n",
    "\n",
    "url = '../../data/vehicles_train.csv'\n",
    "train = \n",
    "train['vtype'] = \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Create random sets of index values for random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# set a seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# create ten bootstrap samples (will be used to select rows from the DataFrame)\n",
    "samples = [np.random.choice(a=14, size=14, replace=True) for _ in range(10)]\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# show the rows for the first decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read in and prepare the vehicle testing data\n",
    "url = '../../data/vehicles_test.csv'\n",
    "test = \n",
    "test['vtype'] = \n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# grow each tree deep\n",
    "treereg = \n",
    "\n",
    "# list for storing predicted price from each tree\n",
    "predictions = []\n",
    "\n",
    "# define testing data\n",
    "X_test = \n",
    "y_test = \n",
    "\n",
    "# grow one tree for each bootstrap sample and make predictions on testing data\n",
    "for sample in samples:\n",
    "    X_train = \n",
    "    y_train = \n",
    "    \n",
    "    y_pred = \n",
    "    predictions\n",
    "\n",
    "# convert predictions from list to NumPy array\n",
    "predictions = \n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "10 rows of prediction for each of the ten samples. 3 columns for each car in the in test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# average predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "\n",
    "y_pred = \n",
    "np.sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's calculate RMSE by training the whole dataset on a Decision Tree Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "treereg = \n",
    "treereg\n",
    "preds = \n",
    "#RMSE\n",
    "np.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Bagged decision trees in scikit-learn (with estimators=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# define the training and testing sets\n",
    "X_train = \n",
    "y_train = \n",
    "X_test = \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# instruct BaggingRegressor to use DecisionTreeRegressor as the \"base estimator\"\n",
    "\n",
    "bagreg = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# fit and predict\n",
    "bagreg\n",
    "y_pred = \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# calculate RMSE\n",
    "np.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Use RandomForest regression to caculate RMSE\n",
    "\n",
    "\n",
    "\n",
    "#Intialize\n",
    "rfe = \n",
    "\n",
    "#Fit\n",
    "\n",
    "\n",
    "#Predictions\n",
    "y_pred = \n",
    "\n",
    "# calculate RMSE\n",
    "np.sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Estimating out-of-sample error\n",
    "\n",
    "For bagged models, out-of-sample error can be estimated without using train/test split or cross-validation\n",
    "\n",
    "On average, each bagged tree uses about **two-thirds** of the observations. For each tree, the **remaining observations** are called \"out-of-bag\" observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# show the first bootstrap sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# show the \"in-bag\" observations for each sample\n",
    "for sample in samples:\n",
    "    print set(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# show the \"out-of-bag\" observations for each sample\n",
    "for sample in samples:\n",
    "    print sorted(set(range(14)) - set(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "How to calculate **\"out-of-bag error\":**\n",
    "\n",
    "1. For every observation in the training data, predict its response value using **only** the trees in which that observation was out-of-bag. Average those predictions (for regression) or take a vote (for classification).\n",
    "2. Compare all predictions to the actual response values in order to compute the out-of-bag error.\n",
    "\n",
    "When n_estimators is sufficiently large, the **out-of-bag error** is an accurate estimate of **out-of-sample error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# compute the out-of-bag R-squared score (not MSE, unfortunately!) for n_estimators=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Estimating feature importance\n",
    "\n",
    "Bagging increases **predictive accuracy**, but decreases **model interpretability** because it's no longer possible to visualize the tree to understand the importance of each feature.\n",
    "\n",
    "However, we can still obtain an overall summary of **feature importance** from bagged models:\n",
    "\n",
    "- **Bagged regression trees:** calculate the total amount that **MSE** is decreased due to splits over a given feature, averaged over all trees\n",
    "- **Bagged classification trees:** calculate the total amount that **Gini index** is decreased due to splits over a given feature, averaged over all trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Building and Tuning Decision Trees and Random Forest Models\n",
    "\n",
    "- Major League Baseball player data from 1986-87: [data](https://github.com/justmarkham/DAT8/blob/master/data/hitters.csv), [data dictionary](https://cran.r-project.org/web/packages/ISLR/ISLR.pdf) (page 7)\n",
    "- Each observation represents a player\n",
    "- **Goal:** Predict player salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# read in the data\n",
    "path = '../../data/hitters.csv'\n",
    "hitters = \n",
    "\n",
    "# remove rows with missing values\n",
    "\n",
    "\n",
    "#View data\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#lower case column names\n",
    "\n",
    "hitters.columns = hitters.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "hitters.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# encode categorical variables as integers\n",
    "hitters['league'] = pd.factorize(hitters.league)[0]\n",
    "hitters['division'] = pd.factorize(hitters.division)[0]\n",
    "hitters['newleague'] = pd.factorize(hitters.newleague)[0]\n",
    "hitters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Scatter plot of years versus hits colored by salary\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "hitters.plot(kind='scatter', x='years', y='hits',\n",
    "             c='salary', cmap=plt.cm.get_cmap('RdBu'), s = 100, alpha = .7,\n",
    "             xlim=(0, 25), ylim=(0, 250), figsize=(9, 7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# define features: exclude career statistics (which start with \"C\") and the response (Salary)\n",
    "feature_cols = [h for h in hitters.columns if h[0] != 'c' and h != 'salary']\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = hitters[feature_cols]\n",
    "y = hitters.salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Predicting salary with a decision tree\n",
    "\n",
    "Find the best max_depth for a decision tree using cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# list of values from 1 - 21 to try for max_depth\n",
    "max_depth_range = \n",
    "\n",
    "# list to store the average RMSE for each value of max_depth\n",
    "RMSE_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of max_depth\n",
    "\n",
    "for depth in max_depth_range:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plot max_depth (x-axis) versus RMSE (y-axis)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(max_depth_range, RMSE_scores, linewidth = 6)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Whats the best max_depth?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# show the best RMSE and the corresponding max_depth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# max_depth=2 was best, so fit a tree using that parameter\n",
    "treereg = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':feature_cols, \n",
    "              'importance':treereg.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Predicting salary with a Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Intialize\n",
    "rfreg = RandomForestRegressor()\n",
    "#Show model details\n",
    "rfreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Tuning n_estimators\n",
    "\n",
    "One important tuning parameter is **n_estimators**, which is the number of trees that should be grown. It should be a large enough value that the error seems to have \"stabilized\". We want to reach a point of diminishing marginal returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# list of values from 10 to 210 in intervals of 10 to try for n_estimators\n",
    "estimator_range = \n",
    "\n",
    "# list to store the average RMSE for each value of n_estimators\n",
    "RMSE_scores = \n",
    "\n",
    "# use 5-fold cross-validation with each value of n_estimators. Will take a while.\n",
    "\n",
    "for estimator in estimator_range:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plot n_estimators (x-axis) versus RMSE (y-axis)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(estimator_range, RMSE_scores)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('RMSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Best estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Tuning max_features\n",
    "\n",
    "The other important tuning parameter is **max_features**, which is the number of features that should be considered at each split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# list of values to try for max_features\n",
    "feature_range = \n",
    "\n",
    "# list to store the average RMSE for each value of max_features\n",
    "RMSE_scores = []\n",
    "\n",
    "# use 5-fold cross-validation with each value of max_features (WARNING: SLOW!)\n",
    "for feature in feature_range:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# plot max_features (x-axis) versus RMSE (y-axis)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(feature_range, RMSE_scores)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel('RMSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# show the best RMSE and the corresponding max_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Fitting a Random Forest with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# max_features=6 is best and n_estimators=150 is sufficiently large\n",
    "rfreg = RandomForestRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# compute feature importances\n",
    "pd.DataFrame({'feature':feature_cols,\n",
    "              'importance':rfreg.feature_importances_}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# compute the out-of-bag R-squared score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Reducing X to its most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# check the shape of X\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# set a threshold for which features to include\n",
    "print \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Use the mean threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# create a new feature matrix that only includes important features\n",
    "X_important = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# check the RMSE for a Random Forest that only includes important features\n",
    "rfreg = RandomForestRegressor(n_estimators=150, max_features=3, random_state=1)\n",
    "scores = cross_val_score(rfreg, X_important, y, cv=10, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# check the RMSE for a Random Forest that includes ALL features ( for comparison )\n",
    "rfreg = RandomForestRegressor(n_estimators=150, max_features=3, random_state=1)\n",
    "scores = cross_val_score(rfreg, X, y, cv=10, scoring='neg_mean_squared_error')\n",
    "np.mean(np.sqrt(-scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Visualizing Decision Trees versus Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Generate fake data that is 400 x 2.\n",
    "data = make_classification(n_samples=400, n_features=2, n_informative=2, n_redundant=0, \n",
    "                    class_sep=.74, random_state = 28)\n",
    "\n",
    "df = pd.DataFrame(data[0], columns=[\"feature1\", \"feature2\"])\n",
    "#Add target variable to df \n",
    "df[\"target\"] = data[1]\n",
    "\n",
    "#Call scatter plot of feature1 vs feature2 with color-encoded target variable\n",
    "\n",
    "plt.figure(figsize=(11, 8))\n",
    "#Color encode target variable\n",
    "colors = df.target.map({0:\"b\", 1:\"r\"})\n",
    "plt.scatter(df.feature1, df.feature2, c = colors, s = 100, alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Assign X and y\n",
    "X = df.drop(\"target\", axis = 1)\n",
    "y = df.target\n",
    "\n",
    "#Fit a Decision Tree model with 5 max_depth on the data.\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "dt.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Decision boundary function\n",
    "def plot_decision_boundary(model, X, y):\n",
    "    X_max = X.max(axis=0)\n",
    "    X_min = X.min(axis=0)\n",
    "    xticks = np.linspace(X_min[0], X_max[0], 100)\n",
    "    yticks = np.linspace(X_min[1], X_max[1], 100)\n",
    "    xx, yy = np.meshgrid(xticks, yticks)\n",
    "    ZZ = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = ZZ >= 0.5\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,7)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax = plt.gca()\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.bwr, alpha=0.2)\n",
    "    ax.scatter(X[:,0], X[:,1], c=y, alpha=0.4, s = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Feed dt model, features and colors\n",
    "plot_decision_boundary(dt, X.values, colors);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Fit RF model on data and visualize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Use estimators = 30\n",
    "rf = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "#Fit model\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Feed rf model, features and colors\n",
    "plot_decision_boundary(rf, X.values, colors);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Resources\n",
    "\n",
    "- http://blog.datadive.net/interpreting-random-forests/\n",
    "- http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/\n",
    "- https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/05.08-Random-Forests.ipynb\n",
    "- https://aysent.github.io/2015/11/08/random-forest-leaf-visualization.html\n",
    "- https://medium.com/rants-on-machine-learning/the-unreasonable-effectiveness-of-random-forests-f33c3ce28883\n",
    "- https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
    "- http://paolaelefante.com/2016/03/a-small-guide-to-random-forest-part-2/\n",
    "- https://www.youtube.com/watch?v=QHOazyP-YlM\n",
    "- https://www.youtube.com/watch?v=loNcrMjYh64\n",
    "- https://machinelearningmastery.com/bagging-and-random-forest-ensemble-algorithms-for-machine-learning/\n",
    "- https://machinelearningmastery.com/implement-bagging-scratch-python/\n",
    "- https://towardsdatascience.com/enchanted-random-forest-b08d418cb411\n",
    "- https://github.com/Miguel75An/Random-Forests-with-Iris-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Classifying Employee Churn with Decision Trees and Random Forest\n",
    "\n",
    "In class exercise in which we will apply both the Decision Trees and Random Forest models to the Employee Churn data. We'll compare and contrast the performances of both models using this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/HR_comma_sep.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
